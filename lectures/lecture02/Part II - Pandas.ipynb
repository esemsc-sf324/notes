{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b593168a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 2: NumPy & Pandas\n",
    "\n",
    "## Part II : Pandas - Data Analysis in Python\n",
    "\n",
    "## James Percival <j.percival@imperial.ac.uk>\n",
    "\n",
    "### Slides based on the Numpy tutorials and work by Dr. Parastoo Salah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55fd15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Doing Spreadsheets to Python\n",
    "\n",
    "- NumPy is great for numerical data\n",
    "- But what if you have data with different types & need to do statistical analysis?\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is an open source library that's built on top of a `NumPy`-like platform called `PyArrow`.\n",
    "\n",
    " Name comes from \"panel data\", econometrics term for data sets that include observations time periods for a fixed set of individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed319530",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pandas is good for:\n",
    "- Fast analysism data cleaning & preparation.\n",
    "- Preprocessing machine learning approaches.\n",
    "- (Relatively) high performance & productivity.\n",
    "- Quick built-in visualization features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3646a47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- It can work with data from a wide variety of sources.\n",
    "- It allows importing data in various formats such as csv, excel, HTML, etc.\n",
    "- It allows a range of data manipulation operations such as `groupby`, `merge`, `concatenation` as well as data cleaning features such as filling, replacing or imputing missing values.\n",
    "- It has for timeseries analysis for both regular and irregular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87a3d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning objectives \n",
    "For the rest of the day we will learn how to use Pandas for data analysis. \n",
    "- The Pandas `Series` object.\n",
    "- DataFrames: Creating, reading and writing to `DataFrame`s.\n",
    "- Indexing of `DataFrame`s & how to slice and reference them.\n",
    "- Arithmetic Operations on `Series` & `DataFrame`s\n",
    "- Extract information from your data through summary functions and maps.\n",
    "- Grouping and sorting data.\n",
    "- `DataType`s and handling missing data.\n",
    "- Renaming, Merging/Joining, and Concatenating.\n",
    "- Built-in visualization features\n",
    "- Timeseries with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a4de9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Panda `Series`\n",
    "- A `Series` works like a NumPy array, except indexed by a label\n",
    "- Behaves a lot like a fast Python dictionary.\n",
    "- It is a one-dimensional array holding data of any (collective) type.\n",
    "- Can index by label, or by position.\n",
    "\n",
    "Let's look at some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c62e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating a Series\n",
    "\n",
    "Pandas is usually imported as `pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df022a6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3cbc9e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You can convert a **list**, **numpy array**, **dictionary** or other **iterable** to a `Series`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d20ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Starting from a `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [100, 200, 300]\n",
    "pd.Series(data = my_list) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ebeab",
   "metadata": {},
   "source": [
    "It looks a lot like a NumPy array, except we're explict we have an index `0 1 2` and data `100 200 300`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b8a7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Key to a Panda Series is that you can change the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['x', 'y', 'z']\n",
    "pd.Series(data=my_list, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb130669",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Starting from a `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ddee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([28, 25.0, 'Brian'])\n",
    "pd.Series(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481f316",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Can change index again\n",
    "\n",
    "labels = ['age', 'mark', 'name']\n",
    "ser = pd.Series(arr, index=labels)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95413926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ser['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddec5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Starting from a Python `dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are easy here:\n",
    "dic = {'x':10.0,'y':20.0,'z':30.0}  #python dictionary\n",
    "pd.Series(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ceb469",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data in a Series\n",
    "\n",
    "Pandas uses Numpy-style data types (also a few of its own). Already seen\n",
    "- integers (int64)\n",
    "- floats (float64)\n",
    "\n",
    "Since we're allowed any Python object, could even use functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not many reasons to do this!\n",
    "pd.Series([sum, print, len])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2625253",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using an Index\n",
    "\n",
    "Let's see some examples of how to grab information from a Series.\n",
    "\n",
    "Let us create two `Series`, `ser1` and `ser2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([10, 20, 30, 40],index = ['X', 'Y','Z', 'T'])                                   \n",
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d4a7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ser2 = pd.Series([10, 20, 50, 40],index = ['X', 'Y','M', 'T'])                                   \n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e1975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1['X'] #just pass in the index label like we would in NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0486423f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Operations are then also done based off of index:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 + ser2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4d8d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  DataFrames: creating, reading, writing\n",
    "\n",
    "A `DataFrame` is a table (think _Excel_ spreadsheet).\n",
    "- It contains an collection of entries, each of which has a certain value.\n",
    "- Each entry corresponds to a row (or record or index) and a column (or field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0b135",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Creating\n",
    "We are using the `pd.DataFrame()` constructor to generate these `DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.random.randn(4,3), index=['A','B','C','D'], columns=['X','Y','Z'])\n",
    "\n",
    "#Common alternative Syntax:\n",
    "#df = pd.DataFrame(randn(4,3),index='A B C D'.split(),columns='X Y Z'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb9986",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Or use a dictionary of columns\n",
    "\n",
    "data = pd.DataFrame({'Course':['NPP','NPP','EDMS','EDMS','CM','CM'],\n",
    "       'Person':['Bob','Sam','Amy','Vanessa','Carl','Sarah'],\n",
    "       'Marks':[70,75,80,65,60,90]},\n",
    "       index=['A','B','C','D','E','F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af95a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211995e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading and writing\n",
    "\n",
    "Being able to create a `DataFrame` or `Series` by hand is useful. \n",
    "\n",
    "Most of the time, won't actually be creating our own data by hand. We'll be working with data that already exists.\n",
    "\n",
    "Pandas has tools to read data in a whole lot of formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec9328",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CSV files\n",
    "\n",
    "Structured datcan be stored in any of a number of different forms and formats. By far the most basic of these is the humble CSV file. When you open a CSV file you get something that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('inputs/df1.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fcc0c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `pd.read_csv()` function is very versatile, with >30 optional parameters . \n",
    "\n",
    "For example, you can see in this dataset that the CSV file has a built-in index, which pandas did not pick up on automatically. To make pandas use that column for the index (instead of creating a new one from scratch), we can specify an index_col."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c34499",
   "metadata": {},
   "source": [
    "We can write a csv file with\n",
    "\n",
    "```python\n",
    "df.to_csv('example', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de8b23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Excel\n",
    "\n",
    "Pandas can read and write excel files (with a few helper packages).\n",
    "\n",
    "Keep in mind, this only imports data. Not formulas or images.\n",
    "\n",
    "Having images or macros may cause this `read_excel` method to crash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8d617",
   "metadata": {},
   "source": [
    "read/write with\n",
    "\n",
    "```python\n",
    "pd.read_excel('Excel_Sample.xlsx',sheetname='Sheet1')\n",
    "\n",
    "df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ec44b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Selection, Assigning data and Indexing\n",
    "\n",
    "## Selection\n",
    "\n",
    "Let's learn the various methods to grab data from a DataFrame.\n",
    "These are the two ways of selecting a specific Series out of a `DataFrame`. \n",
    "\n",
    "The indexing operator `[]` does have the advantage that it can handle column names with reserved characters in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb10c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1323a11",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf133e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass a list of column names\n",
    "df[['Y','Z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b669d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Syntax (Not always possible, not recommended)\n",
    "df.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Y']['A'])\n",
    "df['Y']['A'] == df.loc['A', 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e8c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Index-based selection\n",
    "\n",
    "Pandas indexing works 2 ways:\n",
    "- The first is position-based selection: selecting data based on its numerical position in the data. `.iloc` does this (as does `.at`)\n",
    "- The second is **label-based selection**. In this paradigm, it's the data index value, not its position, which matters. `.loc` does this.\n",
    "\n",
    "Both `loc` and `iloc` are row-first, column-second. This is the same as `numpy` but the opposite native Python, which is column-first, row-second in e.g. lists of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294fa2d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe91ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['B','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59424161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['A','B'],['Z','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad0c86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0,:] #or df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd04074",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a new column:\n",
    "**DataFrame Columns are just Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new'] = df['Z'] + df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23555375",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454edb8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['index_backwards'] = range(len(df), 0, -1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540a1f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b2809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('new', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not done inplace unless specified!\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b73d03",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('new', axis=1, inplace=True)\n",
    "#or \n",
    "#df_newVer = df.drop('new',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9176685",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can also drop rows this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('A', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e20fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "del df['index_backwards']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce90d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Selection\n",
    "\n",
    "An important feature of pandas is conditional selection using bracket notation, very similar to numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbf272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb4312",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[df['Z']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eefb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Z']>0]['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0644a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[df['Z']>0][['Y','X']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e1600",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For two conditions you can use | and & with parenthesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a98b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['X']>0) & (df['Y'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b010812",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc8a02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas has som built-in conditional selectors, two of which we will highlight here.\n",
    "\n",
    "- The first is `.isin`. `isin` is lets you select data whose value \"is in\" a list of values.\n",
    "\n",
    "- The second is `.isnull` (and pair `.notnull`). These methods highlight values which are (aren't) empty or missing (`NaN`/`NA`). For example, to filter out our failed sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Z'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9adb8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More Index Details\n",
    "\n",
    "Let's discuss some more features of indexing, including resetting the index or setting it something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to default 0,1...n index\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4363b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newind = 'one two three four'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc758de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hs_type'] = newind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a5c39",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ddd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Hs_type') # Not inplace by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aed88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Hs_type', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d5598",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-Indexing\n",
    "\n",
    "An index can have more than one level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.DataFrame({'A': [1, 2, 1],\n",
    "        'B': [12., 14., 13.]},\n",
    "        index = pd.MultiIndex.from_arrays([['Player 1', 'Player 1', 'Player2'],\n",
    "                                           ['Test 1', 'Test 2', 'Test 1']])\n",
    "                  )\n",
    "mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38e9b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = {'A':['Class1','Class1','Class1','Class2','Class2','Class2'],\n",
    "     'B':['M1','M1','M2','M2','M1','M1'],\n",
    "       'C':['x','y','x','y','x','y'],\n",
    "       'D':[1,3,2,5,4,1]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.pivot_table(values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a08369",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Operations\n",
    "\n",
    "There are lots of operations it's useful to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1228df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['aa','cc','dd','ee']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761c0d4c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Info on Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f27c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70e105",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated()#."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c1f28",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Drop duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db613b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### statistical information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].mean(numeric_only=True) # or .std() .median(), etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a06eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Summarising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641032a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3c6c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `.map` and `.apply`\n",
    "\n",
    "A **map** is a term, borrowed from maths for a function which takes a set of inputs and \"maps\" them to another set of outputs.\n",
    "\n",
    "In data science often wnt new representations from existing data, or to transform data from existing format it to a new one. Maps ahandle this work, making them extremely important for getting your work done!\n",
    "\n",
    "`map()` is the simple function, which just takes each element and apply a function (**not in place**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7931a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_mean = df['col1'].mean()\n",
    "df['col1'].map(lambda p: p - df_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab8602",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`.apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba099d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_n(x, n):\n",
    "    return x*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col1'].apply(times_n, n=4)\n",
    "df['col1'].apply(times_n, args=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a85852",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['col3'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35267105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget the builtins!\n",
    "\n",
    "df['col2'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1e1a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More on Data Types \n",
    "\n",
    "- You can use the `dtype` property to grab the type of a specific column. \n",
    "- Use `.dtypes` on `DataFrame` to see all data types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9475cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016cc3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Data types tell us how {andas is storing data internally. \n",
    "- `float64` means that it's using a 64-bit floating point number; \n",
    "- `int64` means a similarly sized integer instead.\n",
    "\n",
    "Python strings are stored as objects, just like in numpy (and unlike C-style strings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38674e79",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's possible to convert a column of one type into another wherever such a conversion makes sense by using the `astype()` function.\n",
    "\n",
    "For example, we may transform the points column from its existing `int64` data type into a `float64` data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].astype('float64') # Convesion, not cast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5925fabe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing Values\n",
    "\n",
    "Entries missing values are given the value `NaN`, short for \"Not a Number\". For technical reasons these `NaN` values are always of the `float64` `dtype`.\n",
    "\n",
    "Pandas provides some methods specific to missing data. To select `NaN` entries you can use `pd.isnull()` (or its companion `pd.notnull()`). This is meant to be used thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f829583d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1':[1,2,3,np.nan],\n",
    "                   'col2':[np.nan,555,666,444],\n",
    "                   'col3':['aaa','bbb','ccc','ddd']})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbbcff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846060a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Watch out for effect on maths!\n",
    "\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f74428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a512865",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A':[1,2,np.nan],\n",
    "                  'B':[5,np.nan,np.nan],\n",
    "                  'C':[1,2,3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f209eed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1) # drop columns instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f49833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh=2) # How many allows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e34f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with human-readable notice\n",
    "df.fillna(value='FILL VALUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb646f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with a typical value\n",
    "df['A'].fillna(value=df['A'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9af188",
   "metadata": {},
   "source": [
    "Remember the `replace()` method if you get data with  \"Unknown\", \"Undisclosed\", \"Invalid\", and so on and want `np.NaN`s instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc4852",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Groupby\n",
    "\n",
    "The `groupby()` method allows you to group rows of data together and call aggregate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "data = pd.DataFrame({'Course':['NPP','NPP','EDMS','EDMS','CM','CM'],\n",
    "       'Person':['Bob','Sam','Amy','Vanessa','Carl','Sarah'],\n",
    "       'Marks':[70,75,80,65,60,90]},\n",
    "       index=['A','B','C','D','E','F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec866df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267888d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now you can use the .groupby() method to group rows together based off of a column name. For instance let's group based off of Company. This will create a DataFrameGroupBy object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90237f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Course')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da13e5",
   "metadata": {},
   "source": [
    "You can save this object as a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca443bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_course = df.groupby(\"Course\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca368e98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can call aggregate methods off the object to get new Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1290150",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_course.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b925d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "by_course.std(numeric_only=True) #max() #min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_course.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1429e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "by_course.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f82179",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_course.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c826a",
   "metadata": {},
   "source": [
    "Another `groupby()` method worth mentioning is agg(), which lets you run your own functions on your DataFrame.\n",
    "\n",
    "For example, we can generate a simple statistical summary of the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Course']).agg([len, 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9b30d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Merging, Joining, and Concatenating\n",
    "\n",
    "There are 3 main ways of combining DataFrames together:\n",
    "- Merging\n",
    "- Joining\n",
    "- Concatenating.\n",
    "\n",
    "Let's look at some examples. First, some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703981ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c997be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6848c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                        index=[8, 9, 10, 11])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d8061",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenation\n",
    "\n",
    "Concatenation glues together DataFrames. Want dimensions to match along the axis you are concatenating on.\n",
    "\n",
    "Use `pd.concat` & pass in a list/iterable of DataFrames to stick together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9032d34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a0d7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998444f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#New data for merging\n",
    "\n",
    "left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "   \n",
    "right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                          'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                          'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861385d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a98c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merging\n",
    "\n",
    "The **merge** function allows you to merge DataFrames together using a similar logic as merging SQL Tables together. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left,right, how='inner',on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17ae63",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                        'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "    \n",
    "right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                               'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                                  'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                                  'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69114c42",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d91107",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c9110",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how='outer', on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b17473",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how='right', on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b53004",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how='left', on=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b52381",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joining\n",
    "Joining is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                      index=['K0', 'K1', 'K2']) \n",
    "\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D2', 'D3']},\n",
    "                      index=['K0', 'K2', 'K3'])\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68983d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "left.join(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c4a8b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "left.join(right, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433156f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Pandas can do plots & charts straight from the data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('inputs/df1.csv', index_col=0)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af8e5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram from a Seeis\n",
    "\n",
    "df1['A'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98a811",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter from a dataframe\n",
    "\n",
    "df1.plot.scatter('A', 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99d32c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time Series Analysis\n",
    "\n",
    "Pandas has tools to resample and aggregate temporally indexed data. See `MorePandas.ipynb` for more to play with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f09ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inputs/Tide.csv', index_col='Date',\n",
    "                 parse_dates=True, dayfirst=True) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3be3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.resample(rule='D').mean() # daily mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9512f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hs'].resample('M').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a7448",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "rise": {
   "autolaunch": true,
   "overlay": "<div style=float:right;><img style=width:200px; src=./images/AdaLovelace2.png></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
